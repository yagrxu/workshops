{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据入库"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 连接 OpenSearch 并加载 LLM 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from sagemaker.huggingface.model import HuggingFacePredictor\n",
    "# import boto3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "host = 'search-aiml-bot-rzeucj66zz7ortkojghfgzh2c4.us-east-1.es.amazonaws.com' \n",
    "port = 443\n",
    "region = 'us-east-1' # e.g. us-west-1\n",
    "\n",
    "# credentials = boto3.Session().get_credentials()\n",
    "# auth = AWSV4SignerAuth(credentials, region)\n",
    "auth = (os.environ.get(\"AOS_USER\"), os.environ.get(\"AOS_PWD\")) \n",
    "\n",
    "client = OpenSearch(\n",
    "    hosts = [f'{host}:{port}'],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")\n",
    "\n",
    "\n",
    "predictor = HuggingFacePredictor(\n",
    "  endpoint_name='llm-models'\n",
    ")\n",
    "\n",
    "# 插入数据\n",
    "def update_data(id, data):\n",
    "    response = client.index(\n",
    "        index=index_name,body=data, id=id\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "index_name = 'doc_embeddings'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建索引\n",
    "\n",
    "目前向量模型转化的 vector 的数组长度为 768，所以向量的维度为 `\"dimension\": 768`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'doc_embeddings'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "index_body = {\n",
    "      \"settings\": {\n",
    "        \"index\": {\n",
    "          \"knn\": True\n",
    "        }\n",
    "      },\n",
    "      \"mappings\": {\n",
    "        \"properties\": {\n",
    "          \"content_vec\": {\n",
    "            \"type\": \"knn_vector\",\n",
    "            \"index\": True, \n",
    "            \"dimension\": 1536,\n",
    "            \"method\": {\n",
    "              \"name\": \"hnsw\",\n",
    "              \"space_type\": \"l2\",\n",
    "              \"engine\": \"nmslib\",\n",
    "              \"parameters\": {\n",
    "                \"ef_construction\": 128,\n",
    "                \"m\": 24\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "client.indices.create(index_name, body=index_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除索引\n",
    "client.indices.delete(index=index_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分拆文档并插入 AOS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据插入 - 大学\n",
    "\n",
    "读取文本文件，并按照行进行分片，然后向量化，并插入 AOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = './docs/985-uni.txt'\n",
    "university_file = open(file_name, 'r')\n",
    "\n",
    "lines = university_file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "  line = line.strip()\n",
    "  if line:\n",
    "    print(\"Inserting: {}...\".format(line[:20]))\n",
    "    update_data(None, {\n",
    "      \"text\": line,\n",
    "      \"origion\": file_name,\n",
    "      \"content_vec\": predictor.predict({\"text\": line,\"type\": 2}),\n",
    "    })\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据插入：解决方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "sol_dir = './docs_solutions/'\n",
    "\n",
    "file_list = os.listdir(sol_dir)\n",
    "for file_path in file_list:\n",
    "  file_name = sol_dir + file_path\n",
    "  sol_file = open(file_name, 'r')\n",
    "  lines = sol_file.readlines()\n",
    "  for line in lines:\n",
    "    line = line.strip()\n",
    "    if line:\n",
    "      print(\"Inserting: {}... {}\".format(line[:20], file_name))\n",
    "      update_data(None, {\n",
    "        \"text\": line,\n",
    "        \"origion\": file_name,\n",
    "        \"content_vec\": predictor.predict({\"text\": line,\"type\": 2}),\n",
    "      })\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "openai.api_base = \"http://k8s-chatgpt-ingressp-a104c32ff2-2133206119.ap-southeast-1.elb.amazonaws.com/v1\"\n",
    "\n",
    "\n",
    "def get_emb(txt):\n",
    "    res = openai.Embedding.create(input=txt, model=\"text-embedding-ada-002\")\n",
    "    return res['data'][0]['embedding']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据插入：商品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting: GE 6-Outlet Surge Pr... ./docs_ec/g2.txt\n",
      "Inserting: Kindle Oasis Essenti... ./docs_ec/g3.txt\n",
      "Inserting: V CARRIER 维旺斯 碳纤维笔筒笔... ./docs_ec/g1.txt\n",
      "Inserting: 雅迪新国标电动车座套防雨防晒新款皮革爱玛... ./docs_ec/g4.txt\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "sol_dir = './docs_ec/'\n",
    "\n",
    "file_list = os.listdir(sol_dir)\n",
    "for file_path in file_list:\n",
    "  file_name = sol_dir + file_path\n",
    "  sol_file = open(file_name, 'r')\n",
    "  line = sol_file.read()\n",
    "  line = line.strip()\n",
    "  if line:\n",
    "    print(\"Inserting: {}... {}\".format(line[:20], file_name))\n",
    "    update_data(None, {\n",
    "      \"text\": line,\n",
    "      \"origion\": file_name,\n",
    "      \"content_vec\": get_emb(line),\n",
    "    })\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(sentense):\n",
    "    sentence_vec =  get_emb(sentense)\n",
    "    query_body = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"content_vec\": {\n",
    "                    \"vector\": sentence_vec,\n",
    "                    \"k\": 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = client.search(index=index_name, body=query_body)\n",
    "    result =  map(map_res, response[\"hits\"][\"hits\"])\n",
    "    return list(result)\n",
    "\n",
    "def map_res(obj):\n",
    "    return {\n",
    "        \"id\": obj[\"_id\"],\n",
    "        \"score\": obj[\"_score\"],\n",
    "        \"text\": obj[\"_source\"][\"text\"],\n",
    "        \"origion\": obj[\"_source\"][\"origion\"],\n",
    "\n",
    "    }\n",
    "\n",
    "# search(\"What are the universities of foreign languages\")\n",
    "\n",
    "# search(\"国防科技大学的王牌专业是哪个？\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '0dUiKYkBRau1ZRpy3MUZ',\n",
       "  'score': 0.7312084,\n",
       "  'text': '雅迪新国标电动车座套防雨防晒新款皮革爱玛电车坐垫套防水通用型 【四面弹皮革】圆头 单个前座套\\n品牌： 澳颜莱\\n商品名称：雅迪新国标电动车座套防雨防晒新款皮革爱玛电车坐垫套防水通用型 【四面弹皮革】圆头 类别：平面款表层主材质：皮功能：加热下单需绑定车型：需绑定车型适用季节：四季通用适用场景：商务接待套件类别：前排单座\\n\\n价格 ￥11.72',\n",
       "  'origion': './docs_ec/g4.txt'},\n",
       " {'id': 'qqciKYkBDTiYVUcx1IhR',\n",
       "  'score': 0.6921875,\n",
       "  'text': 'V CARRIER 维旺斯 碳纤维笔筒笔盒线性碳纤维无铅黄铜\\n手工打磨的线性碳纤维和无铅黄铜 长度：180mm 外经：16mm 内径：13mm 重量：30g 产地：意大利 商品包含：原厂包装环保纸盒、说明书、笔筒 \\n价格 728',\n",
       "  'origion': './docs_ec/g1.txt'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search(\"碳纤维笔筒笔盒线性有何特性，价格是多少？\")\n",
    "search(\"四面弹皮革\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对话化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(q):\n",
    "  answers = search(q)\n",
    "  strAnswers = \"\"\n",
    "  references = {}\n",
    "  for an in answers:\n",
    "      strAnswers += an['text'] + \"\\n\"\n",
    "      origion = an['origion']\n",
    "      if origion in references :\n",
    "        references[origion] += 1\n",
    "      else:\n",
    "         references[origion] = 1\n",
    "  ori_prompt = f\"\"\"\n",
    "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{strAnswers}\n",
    "\n",
    "Question: {q}\n",
    "            \n",
    "Helpful Answer:\n",
    "\n",
    "  \"\"\"\n",
    "  # print(\"Prompt: \")\n",
    "  # print(ori_prompt)\n",
    "\n",
    "  print(\"问题: \", q)\n",
    "  a = predictor.predict({\"text\": ori_prompt,\"type\": 8})\n",
    "\n",
    "  return a, references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题:  碳纤维笔筒笔盒线性有何特性，价格是多少？\n",
      "回答： 线性碳纤维笔筒笔盒是一种由碳纤维和无铅黄铜手工打磨而成的产品，具有以下特性：\n",
      "\n",
      "1. 轻量化：采用碳纤维材质，质量轻，方便携带。\n",
      "2. 高强度：碳纤维具有很高的强度和刚性，能够承受较大的压力和摩擦力。\n",
      "3. 耐腐蚀：无铅黄铜材质不含有害物质，能够抵御酸碱等化学物质的侵蚀。\n",
      "4. 耐磨性：手工打磨的线性碳纤维和无铅黄铜表面具有很高的摩擦系数，耐磨性优异。\n",
      "5. 美观质感：采用意大利制造，外观设计精美，质感出众。\n",
      "\n",
      "根据提供的信息，线性碳纤维笔筒笔盒的价格为728元。\n",
      "引用： {'./docs_ec/g1.txt': 1, './docs_ec/g4.txt': 1, './docs_ec/g3.txt': 1, './docs_ec/g2.txt': 1}\n"
     ]
    }
   ],
   "source": [
    "answer01 = ask(\"碳纤维笔筒笔盒线性有何特性，价格是多少？\")\n",
    "\n",
    "print(\"回答：\", answer01[0])\n",
    "print(\"引用：\", answer01[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题:  亚马逊的阅读器有什么特性，价格是多少？\n",
      "回答： 亚马逊的阅读器是一款电子书阅读器，具有以下特性：\n",
      "\n",
      "1. 它可以阅读各种电子书格式，如 Kindle、Audible、Overdrive、公共图书馆等。\n",
      "2. 它支持阅读自定义文本，包括注释、批注和手写笔记。\n",
      "3. 它可以在 PDF、Word、Excel 和 plain text 等格式下阅读。\n",
      "4. 它支持批注、填写表格和朗读文本。\n",
      "5. 它支持将阅读内容导出为 PDF、Word、Excel 和 plain text 等格式。\n",
      "6. 它支持在阅读过程中进行搜索、查找和引用。\n",
      "7. 它支持将阅读内容导出为 Audible 和 MP3 格式。\n",
      "\n",
      "亚马逊的阅读器的价格因型号和特性和销售地区而异。以下是不同型号的价格范围：\n",
      "\n",
      "1. Kindle Oasis: $239.99\n",
      "2. Kindle Paperwhite: $109.99\n",
      "3. Kindle HD: $139.99\n",
      "4. Kindlego: $109.99\n",
      "\n",
      "请注意，这里提供的价格是基于 Amazon 上的建议价格，实际价格可能因折扣、促销和销售地区而有所不同。\n",
      "引用： {'./docs_ec/g3.txt': 1, './docs_ec/g4.txt': 1, './docs_ec/g1.txt': 1, './docs_ec/g2.txt': 1}\n"
     ]
    }
   ],
   "source": [
    "answer01 = ask(\"亚马逊的阅读器有什么特性，价格是多少？\")\n",
    "\n",
    "print(\"回答：\", answer01[0])\n",
    "print(\"引用：\", answer01[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask(\"What is the number 1 comprehensive university in China?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask(\"华东师范大学在中国排名第几？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer01 = ask(\"基本农田保护方案是什么？\")\n",
    "\n",
    "print(\"回答：\", answer01[0])\n",
    "print(\"引用：\", answer01[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer01 = ask(\"你有城市停车运营解决方案吗，具体是怎么运作的？\")\n",
    "\n",
    "print(\"回答：\", answer01[0])\n",
    "print(\"引用：\", answer01[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer01 = ask(\"How to manage the hospital, do you have a specific plan?\")\n",
    "\n",
    "print(\"回答：\", answer01[0])\n",
    "print(\"引用：\", answer01[1])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
